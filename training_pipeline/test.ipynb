{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Surgery\n",
      "PREOPERATIVE DIAGNOSES:,1.  Right ankle trimalleolar fracture.,2.  Right distal tibia plafond fracture with comminuted posterolateral impacted fragment.,OPERATIVE PROCEDURE:  ,Delayed open reduction internal fixation with plates and screws, 6-hole contoured distal fibular plate and screws reducing posterolateral malleolar fragment, as well as medial malleolar fragment.,POSTOPERATIVE DIAGNOSES:,1.  Right ankle trimalleolar fracture.,2.  Right distal tibia plafond fracture with comminuted posterolateral impacted fragment.,TOURNIQUET TIME: , 80 minutes.,HISTORY: , This 50-year-old gentleman was from the area and riding his motorcycle in Kentucky.,The patient lost control of his motorcycle when he was traveling approximately 40 mile per hour.  He was on a curve and lost control.  He is unsure what exactly happened, but he thinks his right ankle was pinned underneath the motorcycle while he was sliding.  There were no other injuries.  He was treated in Kentucky.  A close reduction was performed and splint applied.  Orthopedic surgeon called myself with regards to this patient's fracture management and suggested a CT scan.  The patient returned to Ohio and his friend drove him all the way from Kentucky to Northwest Ohio overnight.  The patient showed up in the emergency department where a CT scan was asked to be performed.  This was performed and reviewed.  The patient, however, had significant amount of soft tissue swelling and therefore he was asked to follow up in 2 days.  At this time, he still had significant swelling, but because of the amount of swelling that he had particularly with the long car ride for many hours with his leg dependent, it was felt to be best to wait.,Indeed after 7 days, the patient started to develop fracture blisters on the posterior medial aspect of his ankle with large blisters measuring approximately 2 to 3 inches.  The patient was x-rayed in the office.  He had lost some of his reduction.  Therefore, he was re-reduced at approximately 7 days and then each time the patient had examination of tissues, he was re-reduced just to keep the pressure off the skin.,An x-ray showed the distal fibular fracture starting at the mortise region laterally.  It appeared as an abduction type injury with minimal rotation.  This was comminuted, fragmented, and impacted.,The medial malleolus fracture was an avulsion type.  The syndesmosis appeared to be intact.  This appeared as an AO type B fracture.  However, this was not a rotational injury.,There is a posterior malleolar fragment attached to the distal fibular fragment, which appeared to be avulsed as well, but comminuted.  CT scan revealed a more serious fracture with an anterior as well as posterior plafond fracture of an anterior fragment, which was undisplaced in the posterior medial corner.  A posterior Tillaux fragment appeared to be separate.  However, in this area, there was significant comminution in the mid portion of the ankle joint.,There were many fragments and defects in this region.,The medial mortise however appeared to be intact with regards to the tibial plafond even though there was an anterior undisplaced fragment.,We discussed delayed open reduction internal fixation with the patient.  He understood the risk of surgery including infection, decreased range of motion, stiffness, neurovascular injury, weakness, and numbness.  We discussed seriously the risk of osteoarthritis because of the comminution in the intraarticular surface shown on the CT scan.  We discussed deep vein thrombosis, pulmonary embolism, skin slough, skin necrosis, infection, and need for second surgery.  We discussed shortening, decreased strength, limited use, disability of operative extremity, malunion, nonunion, compartment syndrome, stiffness of the operative extremity, numbness, and weakness.  Examination of the patient revealed that he had slightly decreased sensation on the dorsum of his foot.,The patient was able to flex and extend his toes, had good capillary refill, good dorsalis pedis, and posterior tibial pulse.,The patient's tissues were edematous and we has waited approximately 10 days before performing the surgery when the skin could be wrinkled anteriorly.  We discussed his incision, the medial incision as well as lateral incision and the lateral incision would be more posterolateral to maintain a bridge of at least 6 to 8 cm between the 2 incisions.  We did discuss the skin slough as well as skin necrosis, particularly medially where the most skin pressure was because of displacement laterally.  He understood the posterolateral comminution of the tibial plafond, which would be reduced by aligning up the cortex posteriorly.,We discussed the posterolateral approach with reduction of the fibula.  We discussed that likely the distal fibula would not be removed completely to assess the articular surface as this would likely comminute the fibula, even more fragmentation would occur, and would not be able to obtain an anatomic reduction.  He understood this distal fibular fracture was comminuted and there were missing fragments of bone because they were impacted into intramedullary cancellous space.  With this, the patient understood that the hardware may necessitate removal as well in the future.  We discussed hardware irritation.  We also discussed risk of osteoarthritis, which was nearly 100% particularly because of comminution of this area posteriorly.  With these risks discussed and listed on the consent, the patient wanted the procedure.,OPERATIVE NOTE:,  The patient was brought to operating theater and given successful general anesthetic.  His right leg was prepped and draped in the usual fashion.  Before prep and drape was performed, a close reduction was tried to be obtained to see whether there was any obstruction to reduction.  It was felt that at one point the posterior tibialis tendon may be intraarticular.,The reduction appeared to line up.  However, there was significant gap of approximately 1.5 to 2 cm between the avulsed medial malleolus fragment and distal tibia.,A lateral incision was made over the fracture site approximately 8 cm long and was taken to subcutaneous tissue.  The superficial peroneal nerve was seen and this was avoided.  The incision was placed posterolateral to fibula.,This was to ensure good flap of tissue between the 2 incisions medial and laterally.  The fracture was seen.  The fracture was elevated and medialized and de-rotated.  The anterior portion of the distal fibula was significantly comminuted with defect.  The posterior aspect was still intact.  However, there were multiple fracture lines demonstrating a crush-type injury.  This was reduced manually.  At this point, dissection was performed bluntly behind the peroneal tendons in between this and flexor hallucis longus tendon.  No sharp dissection was performed.  The posterior malleolar fragment was palpated with the distal fibula reduced.  The posterior malleolar fragment appeared to be reduced as well.,X-ray views confirmed this.,An incision was made, standard incision, curvilinear, medially distal to the medial corner of the mortise and curving anterior and posteriorly around the tip of the medial malleolus.  This was taken only through subcutaneous tissue.  The saphenous vein was found, dissected out.  Its branches were cauterized.  Penrose drain was placed around this.,Dissection was undertaken.  The periosteal tissue was seen and was invaginated into the joint.,This was recovered and flipped back on both sides.  Next, the towel clip was used.  Ends were freshened up using irrigation.  The joint surface appeared to be congruent anteriorly and posteriorly medially.,Anatomic reduction was performed in the medial malleolus using 2 mm K-wires and exchanging these for a 35 mm and a 40 mm, anterior and posterior respectively, partially threaded cancellous screws.  Anatomic reduction was gained.  X-rays were taken showing excellent anatomic reduction.  Next, attention was drawn towards the fibula.  Standard 6-hole one-third tubular plate was applied to this.  Again, this was more of a transverse impacted fracture.  Therefore, interfragmentary screw on an angle could not be used.,The posterior cortex was used to assess anatomic reduction.  Screws were placed.  It was used as a spring plate pushing the distal fibular fragment medially.,Screw holes were filled.  They were double-checked.  Screws had excellent purchase and were tightened up.  At this point, lateral views were taken as well as palpation of posterior lateral fragment was performed in the plafond.  This appeared to show anatomic reduction and did not appear to be a step on the articular surface or the posterior cortex of the distal tibia.,The screw was then placed from anterior medial to posterior lateral into this comminuted fragment.,A 2 mm K-wire was used.  Finger was placed on this fragment and the pin was advanced even before the finger.  X-ray views could show the posterior cortex and location of the pin.  This was then exchanged for a 55 mm partially threaded cancellous screw after tapping was performed.  This was double checked to ensure good positioning and this was so.  On the lateral view, we could see this was not in the joint.  AP views and mortise views showed this was not in the joint.  One could palpate this as well.  The screw was placed slightly proximal to distal in the anteroposterior plane.  At the distal tip of it, it was just in the subchondral bone but not in the joint.  There was slight to excellent purchase of this posterior lateral fragment.  Wounds were copiously irrigated followed by closing using 2-0 Vicryl in inverted fashion followed by staples to skin.  Adaptic, 4 x 4s, abdominal pad was placed on wound, held in place with Kerlix followed by an extensor bandage.  Posterior splint was placed on the patient.  The patient's leg was placed in neutral position.  Significant amount of cast padding were used and large bulky trauma ABD type dressings.  The heel was padded and leg was padded with approximately 2 inches of padding.  Tourniquet was deflated.  The patient had good capillary refill, good pulses, and the patient returned to recovery room in stable condition with no complications.  Physician assistant assisted during the case with retracting as well as holding the medial malleolar fragment and fragments in position while placement screws were applied.  Positioning of the leg was accomplished by the physician assistant.  As well, physician assistant assisted in transport of patient to and from the recovery room, assisted in cautery as well as dissection and retraction of tissue.  The patient is expected to do well overall.  He does have an area of comminution shown on the CT scan.  However, by x-rays, it appears that there is anatomic reduction gained at this posterolateral fragment.  Nonetheless, this area was crushed and the patient will have degenerative changes in the future caused by this crushing area.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/mtsamples.csv\")\n",
    "\n",
    "idx = np.random.randint(len(df))\n",
    "input_txt = df.loc[idx].transcription\n",
    "category = df.loc[idx].medical_specialty\n",
    "print(category)\n",
    "print(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Orthopedic']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"31-2023-04-05-07-46-59-107\"\n",
    "content_type = \"text/csv\" # \"application/json\" #\n",
    "accept = \"application/json\" #\"text/csv\"\n",
    "# payload = \"test\"#json.dumps({\"instances\":[\"test\"]})\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # CustomAttributes=custom_attributes,\n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=input_txt,\n",
    ")\n",
    "\n",
    "json.loads(response[\"Body\"].read())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch inference (Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_approved_model(model_package_group_name):\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    df = pd.DataFrame(sm_client.list_model_packages(\n",
    "        ModelPackageGroupName=model_package_group_name)[\"ModelPackageSummaryList\"])\n",
    "    \n",
    "    return df.loc[df.ModelApprovalStatus == \"Approved\"].iloc[0].ModelPackageArn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: 31-2023-04-05-08-34-50-498\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "default_bucket = session.default_bucket()\n",
    "\n",
    "model_name = \"22-2023-04-03-13-43-05-767\"\n",
    "input_data_path = f\"s3://{default_bucket}/data/test.csv\"\n",
    "output_data_path = f\"s3://{default_bucket}/data/out\"\n",
    "CONTENT_TYPE_CSV = 'text/csv'\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "role_arn = iam.get_role(RoleName=f'101436505502-sagemaker-exec')['Role']['Arn']\n",
    "model_package_group_name=\"training-pipelineModelGroup\"\n",
    "\n",
    "# model_package_arn = \"arn:aws:sagemaker:eu-west-3:101436505502:\" \\\n",
    "#                         f\"model-package/training-pipelineModelGroup/latest\"\n",
    "\n",
    "model_package_arn = get_latest_approved_model(model_package_group_name)\n",
    "\n",
    "# load model\n",
    "model = sagemaker.ModelPackage(role=role_arn, model_package_arn=model_package_arn,\n",
    "                         sagemaker_session=session)\n",
    "\n",
    "# create transformer\n",
    "transformer =model.transformer(\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.g4dn.xlarge',\n",
    "    strategy = 'SingleRecord',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = output_data_path,\n",
    "    accept = CONTENT_TYPE_CSV,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: 31-2023-04-05-08-35-01-493\n"
     ]
    },
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTransformJob operation: The account-level service limit 'ml.g4dn.xlarge for transform job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b8/mx2blhp93k7blwkppkkv1w_r0000gn/T/ipykernel_71495/3872926404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m transformer.transform(data = input_data_path, \n\u001b[1;32m      2\u001b[0m                         \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONTENT_TYPE_CSV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                         split_type = 'Line')\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mexperiment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mmodel_client_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mbatch_data_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, transformer, data, data_type, content_type, compression_type, split_type, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtransform_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, job_name, model_name, strategy, max_concurrent_transforms, max_payload, env, input_config, output_config, resource_config, experiment_config, tags, data_processing, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m   2926\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m     def _create_model_request(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   4811\u001b[0m             \u001b[0mfunc_name\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0mintercepting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4812\u001b[0m         \"\"\"\n\u001b[0;32m-> 4813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4815\u001b[0m     def _create_inference_recommendations_job_request(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   2924\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating transform job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transform request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2926\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/aws_nimbus_env/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTransformJob operation: The account-level service limit 'ml.g4dn.xlarge for transform job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "transformer.transform(data = input_data_path, \n",
    "                        content_type = CONTENT_TYPE_CSV, \n",
    "                        split_type = 'Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = boto3.client('sagemaker')\n",
    "# c.list_model_packages(ModelPackageGroupName=\"training-pipelineModelGroup\")\n",
    "\n",
    "\n",
    "# transform_job = sagemaker.transformer.Transformer(\n",
    "#     model_name = model_name,\n",
    "#     instance_count = 1,\n",
    "#     instance_type = 'ml.g4dn.xlarge', # ml.g4dn.xlarge\n",
    "#     strategy = 'SingleRecord',\n",
    "#     assemble_with = 'Line',\n",
    "#     output_path = output_data_path,\n",
    "#     base_transform_job_name='inference-pipelines-batch',\n",
    "#     sagemaker_session=session,\n",
    "#     accept = CONTENT_TYPE_CSV)\n",
    "\n",
    "# transform_job.transform(data = input_data_path, \n",
    "#                         content_type = CONTENT_TYPE_CSV, \n",
    "#                         split_type = 'Line')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\") -> None:\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "\n",
    "    def tokenize(self, txt_input):\n",
    "        return self.tokenizer.encode(txt_input, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=40,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (886) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs\u001b[39m.\u001b[39mlogits\u001b[39m.\u001b[39mcpu(), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m y_pred\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:759\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    757\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 759\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[1;32m    760\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    761\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    762\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    763\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    764\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    765\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    766\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    769\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:578\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    575\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[1;32m    580\u001b[0m     x\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m    581\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    586\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:130\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    127\u001b[0m word_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings(input_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m embeddings \u001b[39m=\u001b[39m word_embeddings \u001b[39m+\u001b[39;49m position_embeddings  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    131\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (886) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "tok = MyTokenizer()\n",
    "# input = tok.tokenizer(input_txt, padding=\"max_length\", return_tensors='pt', truncation=True)\n",
    "input = tok.tokenizer(input_txt, return_tensors='pt')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "input.to(device)\n",
    "outputs = model(**input)\n",
    "y_pred = torch.argmax(outputs.logits.cpu(), dim=1)\n",
    "y_pred\n",
    "# [config.MEDICAL_CATEGORIES[i.item()] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_nimbus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
